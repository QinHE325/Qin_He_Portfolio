{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35098911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b157c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature enigineering \n",
    "train_df = pd.read_csv('train.csv')\n",
    "train_df[\"train\"] = 1\n",
    "test_df = pd.read_csv('test.csv')\n",
    "test_df[\"train\"] = 0\n",
    "df = pd.concat([train_df,test_df],sort = False)\n",
    "# numeric encoding \n",
    "le = preprocessing.LabelEncoder()\n",
    "data = df.copy()\n",
    "# encoding catgorical to numeric\n",
    "data[\"Host_response_time\"] = le.fit_transform(df[\"Host_response_time\"])\n",
    "data[\"Host_is_superhost\"] = le.fit_transform(df[\"Host_is_superhost\"])\n",
    "data[\"Host_has_profile_pic\"] = le.fit_transform(df[\"Host_has_profile_pic\"])\n",
    "data[\"Host_identity_verified\"] = le.fit_transform(df[\"Host_identity_verified\"])\n",
    "data[\"Month\"] = le.fit_transform(df[\"Month\"]) + 1\n",
    "data[\"Price\"] = pd.to_numeric(data[\"Price\"].str.replace('[^\\dA-Za-z]', '',regex = True))/100\n",
    "# one-hot encoding\n",
    "dummy_df = pd.get_dummies(df[[\"Neighbourhood\",\"Room_type\"]],columns=[\"Neighbourhood\",\"Room_type\"])\n",
    "data = pd.concat([data,dummy_df],axis = 1)\n",
    "data = data.drop(columns=[\"Neighbourhood\",\"Room_type\",\"Property_type\"])\n",
    "# create column with number of bathroom\n",
    "data[\"Bathroom_number\"] = pd.to_numeric(data[\"Bathrooms_text\"].str.lower().str.replace(\"half\",\"0.5\").str.replace(r\"[a-zA-Z,-]\", '',regex = True))\n",
    "# column indicating if this room has private bath\n",
    "private_bath = data[\"Bathrooms_text\"].str.find(\"private\") + 1\n",
    "data[\"Have_Private_Bath\"] = private_bath \n",
    "data[\"Have_Private_Bath\"][data[\"Have_Private_Bath\"]>0] = 1\n",
    "data = data.drop(columns=[\"Bathrooms_text\"])\n",
    "# replace true/false with 1/0\n",
    "data.loc[data[\"Instant_bookable\"] == \"t\",\"Instant_bookable\"] = 1\n",
    "data.loc[data[\"Instant_bookable\"] == \"f\",\"Instant_bookable\"] = 0\n",
    "data[\"Instant_bookable\"] = pd.to_numeric(data[\"Instant_bookable\"])\n",
    "# Get back the original train and test\n",
    "train = data.loc[data[\"train\"] == 1].drop(columns = [\"id\",\"train\"])\n",
    "test = data.loc[data[\"train\"] == 0].drop(columns = [\"id\",\"train\"])\n",
    "\n",
    "# impute missing data with mean\n",
    "train_data = train.drop(columns = [\"Decision\"])\n",
    "test_data = test.drop(columns=[\"Decision\"])\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean.fit(train_data)\n",
    "train_data = pd.DataFrame(imp_mean.transform(train_data))\n",
    "test_data = pd.DataFrame(imp_mean.transform(test_data))\n",
    "# make sure all columns are imputed\n",
    "print(train_data[train_data.columns[train_data.isna().any()]].shape[1],\" columns of train has NaN\")\n",
    "print(test_data[test_data.columns[test_data.isna().any()]].shape[1],\" columns of test has NaN\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b00a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations among predictors\n",
    "corr = train_df.drop(columns = [\"id\",\"Decision\",\"train\"]).corr()\n",
    "# create heatmap\n",
    "ax = sns.heatmap(corr, vmin=-1, vmax=1, center=0,cmap=\"GnBu\",square=True\n",
    ")\n",
    "# set size\n",
    "sns.set(rc = {'figure.figsize':(5,5)})\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1d8efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split on training set\n",
    "X = train_data\n",
    "y = np.array(train[\"Decision\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=671)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc04d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scale_train = scaler.transform(X_train)\n",
    "scale_test = scaler.transform(X_test)\n",
    "\n",
    "# svm \n",
    "start = time.time()\n",
    "# parameter space\n",
    "param_grid = {'C': [0.1,1,5,10,50,100],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(scale_train,y_train)\n",
    "end = time.time()\n",
    "print(\"running time is\",end-start,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac395730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for visualization included in report\n",
    "# hyperparameter only include C\n",
    "param_grid = {'C': [0.1,1,5,10,50,100]}\n",
    "# fix kernel = rbf\n",
    "grid = GridSearchCV(SVC(kernel = \"rbf\"),param_grid,refit=True,verbose=2)\n",
    "grid.fit(scale_train,y_train)\n",
    "\n",
    "loss = grid.cv_results_[\"mean_test_score\"]\n",
    "plt.plot([0.1,1,5,10,50,100],loss)\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"CV Loss\")\n",
    "plt.title(\"rbf\" +  \" CV LOSS\")\n",
    "\n",
    "# fix kernel = poly\n",
    "grid = GridSearchCV(SVC(kernel = \"poly\"),param_grid,refit=True,verbose=2)\n",
    "grid.fit(scale_train,y_train)\n",
    "loss = grid.cv_results_[\"mean_test_score\"]\n",
    "plt.plot([0.1,1,5,10,50,100],loss)\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"CV Loss\")\n",
    "plt.title(\"poly\" +  \" CV LOSS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582eb6e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CV results for best svm\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "best_prediction = grid.predict(scale_test)\n",
    "accuracy_score(y_test,best_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7830d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC for Best SVM\n",
    "best_svm = SVC(C = 10,kernel='rbf').fit(scale_train,y_train)\n",
    "metrics.plot_roc_curve(best_svm,scale_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ee8bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost\n",
    "start = time.time()\n",
    "xg_clf = xgb.XGBClassifier(objective ='binary:logistic',\n",
    "                             eval_metric = \"logloss\",\n",
    "                           use_label_encoder=False)\n",
    "param_grid = {'n_estimators' : [20,50,100,150,200,250,300],\n",
    "              'max_depth': range(1,30,2)\n",
    "             }\n",
    "grid = GridSearchCV(xg_clf,param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bbf92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best params for the 2 parameters above\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8776357",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set results above as fixed values\n",
    "# keep tuning the other 3 parameters\n",
    "xg_clf = xgb.XGBClassifier(objective ='binary:logistic',\n",
    "                             eval_metric = \"logloss\",n_estimators = 150,\n",
    "                           max_depth = 7,\n",
    "                           use_label_encoder=False)\n",
    "param_grid = {'learning_rate' : np.arange(0.01,0.2,0.01),\n",
    "              'min_child_weight': range(1,10,1),\n",
    "              'lambda' : np.arange(0.1,1.1,0.1)\n",
    "             }\n",
    "grid = GridSearchCV(xg_clf,param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "print(\"running time is\",end-start,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a726a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23859aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best estimate xgboost\n",
    "best_xgb = xgb.XGBClassifier(objective ='binary:logistic',\n",
    "                             eval_metric = \"logloss\",n_estimators = 150,\n",
    "                           max_depth = 7,reg_lambda = 0.2,learning_rate = 0.17,min_child_weight = 1,\n",
    "                           use_label_encoder=False)\n",
    "best_xgb.fit(X_train,y_train)\n",
    "preds = best_xgb.predict(X_test)\n",
    "accuracy_score(y_test,preds)\n",
    "# plot roc\n",
    "metrics.plot_roc_curve(best_xgb,X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7826a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for visualization included in report\n",
    "# fix others; vary n estimators\n",
    "param_grid = {'n_estimators' : [20,50,100,150,200,250,300]}\n",
    "grid = GridSearchCV(xgb.XGBClassifier(objective ='binary:logistic',\n",
    "                             eval_metric = \"logloss\",\n",
    "                           max_depth = 7,reg_lambda = 0.2,learning_rate = 0.17,min_child_weight = 1,\n",
    "                           use_label_encoder=False),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "loss = grid.cv_results_[\"mean_test_score\"]\n",
    "plt.plot([20,50,100,150,200,250,300],loss)\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"CV Loss\")\n",
    "plt.title( \"CV LOSS With N estimators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c577c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for visualization included in report\n",
    "# fix others; vary n max_depth\n",
    "param_grid = {'max_depth': range(1,30,2)}\n",
    "grid = GridSearchCV(xgb.XGBClassifier(objective ='binary:logistic',\n",
    "                             eval_metric = \"logloss\",n_estimators = 150,\n",
    "                           reg_lambda = 0.2,learning_rate = 0.17,min_child_weight = 1,\n",
    "                           use_label_encoder=False),param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "loss = grid.cv_results_[\"mean_test_score\"]\n",
    "plt.plot([*range(1,30,2)],loss)\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"CV Loss\")\n",
    "plt.title( \"CV LOSS With Max Depth N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d203b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# random forest\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "RF_clf = RandomForestClassifier(random_state=671)\n",
    "param_grid = {'max_depth': [10, 20, 30, 40, 50, None],\n",
    "              'n_estimators': [10,50,100,150,200],\n",
    "              'max_features': ['log2', 'sqrt',None]\n",
    "             }\n",
    "grid = GridSearchCV(RF_clf,param_grid,refit=True,verbose=2)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"running time is\",end-start,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2f6bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "pred = grid.predict(X_test)\n",
    "accuracy_score(pred,y_test)\n",
    "# get best random forest\n",
    "best_rf = RandomForestClassifier(random_state=671,max_depth = 20,max_features=\"sqrt\",n_estimators = 150).fit(X_train,y_train)\n",
    "# plot roc\n",
    "metrics.plot_roc_curve(best_rf,X_test, y_test) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
